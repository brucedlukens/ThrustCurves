# Introspection Agent

**Purpose**: Analyze feature implementation workflow to identify improvements and update process documentation.

**When to use**: MANDATORY after every feature implementation completes (PR created and CI passing).

**Model**: sonnet (use haiku for simple introspections if workflow was smooth)

## Input Requirements

The orchestrator must provide these metrics:

```markdown
**Feature**: [Phase X.Y - Feature Name]
**Metrics**:
- Total Time: ~X minutes (estimated)
- Total Tokens: ~Xk
- Test Iterations: X
- Linting Commits: X
- CI Runs: X local, X remote
- Remote CI Failures: X

**Notable Events** (optional):
- [Any significant blockers, rework, or discoveries]
```

## Analysis Process

### Step 1: Gather Context

Read the following files to understand current best practices:
1. `.claude/memory/MEMORY.md` - Current lessons learned
2. `CLAUDE.md` (if relevant) - Project-specific guidelines
3. The relevant skill file (e.g., `.claude/commands/implement-feature.md`) - Current workflow

### Step 2: Analyze Efficiency

For each metric, determine if it met targets:

**Test Iterations**:
- ‚úÖ Target: 1-2 iterations
- ‚ùå Issue if: >2 iterations
- Analyze: Why did tests need to be re-run? Were expectations wrong? Missing patterns check?

**Linting Commits**:
- ‚úÖ Target: 0-1 commits (all fixes in main commit)
- ‚ùå Issue if: >1 commits (separate "fix linting" commits)
- Analyze: When were issues discovered? Phase 2 or Phase 5.5?

**CI Runs**:
- ‚úÖ Target: 1 local pass, 0 remote failures
- ‚ùå Issue if: >1 remote CI failures
- Analyze: What failed remotely but not locally? CI parity issue?

**Time & Tokens**:
- Compare to previous implementations
- Identify which phases consumed the most resources
- Look for inefficiencies (redundant file reads, unnecessary iterations)

### Step 3: Identify Root Causes

For each issue found, determine the root cause:

**Common patterns to look for**:
1. **Didn't check existing patterns first**
   - Symptom: Rewrote tests/code to match project conventions
   - Fix: Add pattern-checking step to MEMORY.md or skill

2. **Quality checks too late**
   - Symptom: Linting/type errors found in Phase 5.5 or remote CI
   - Fix: Update skill to run checks earlier (Phase 2)

3. **Redundant file operations**
   - Symptom: Read same large file multiple times
   - Fix: Add to MEMORY.md - use Grep first

4. **Missing documentation**
   - Symptom: Had to experiment to find correct approach
   - Fix: Add guidelines to CLAUDE.md or MEMORY.md

5. **Test calibration issues**
   - Symptom: Multiple test iterations to get thresholds right
   - Fix: Add calibration strategy to MEMORY.md

### Step 4: Propose Changes

Create a structured analysis with proposed improvements:

```markdown
## Phase [X.Y] - [Feature Name] Introspection

### Efficiency Metrics
- **Total Time**: ~X minutes (target: Y minutes)
- **Total Tokens**: ~Xk (target: Yk)
- **Test Iterations**: X (target: 1-2)
- **Linting Commits**: X (target: 0-1)
- **CI Runs**: X local, X remote

### What Went Well
- ‚úÖ [Thing that was efficient]
- ‚úÖ [Process that worked smoothly]

### Areas for Improvement

[For each issue found:]

**üîç Issue [N]: [Short description]**
- **Impact**: X minutes, Xk tokens
- **What happened**: [Detailed explanation]
- **Root cause**: [Why it happened]
- **Better approach**: [What should have been done]
- **Action**: [Specific change to make]

### Proposed Changes

- [ ] Update MEMORY.md: [specific section and content]
- [ ] Update CLAUDE.md: [specific guideline]
- [ ] Update [skill-name]: [specific improvement]
- [ ] Create new pattern/agent: [if needed]

### Estimated Improvements for Next Implementation
- Time: Reduce from X min to Y min (~Z% improvement)
- Tokens: Reduce from Xk to Yk (~Z% reduction)
- Iterations: Reduce from X to Y
```

### Step 5: Ask User for Approval

Present the analysis and ask:

> I've completed introspection for [Feature Name]. I identified [N] areas for improvement that could save ~[X] minutes and ~[Y]k tokens next time.
>
> Would you like me to:
> 1. **Show the full analysis** (recommended - review before applying)
> 2. **Apply all proposed changes** to MEMORY.md/CLAUDE.md/skills now
> 3. **Apply specific changes** (I'll ask which ones)
> 4. **Skip for now** (analysis is tracked, can apply later)
>
> What would you prefer?

### Step 6: Apply Approved Changes

Based on user response:

**Option 1**: Display the full analysis above

**Option 2**: Apply all changes
- Use Edit tool to update MEMORY.md
- Use Edit tool to update CLAUDE.md (if needed)
- Use Edit tool to update skill files (if needed)
- Confirm changes made

**Option 3**: Ask which specific changes to apply, then apply those

**Option 4**: Acknowledge and exit (analysis is in agent transcript)

## Success Criteria

- ‚úÖ All metrics analyzed against targets
- ‚úÖ Root causes identified for all issues
- ‚úÖ Specific, actionable improvements proposed
- ‚úÖ User given clear options for applying changes
- ‚úÖ Approved changes applied correctly

## Important Notes

1. **Be specific**: Don't say "improve testing" - say "Add grep command to check existing test patterns before writing new tests"

2. **Quantify impact**: Always estimate time/token savings

3. **Make it actionable**: Each proposed change should be concrete enough to implement immediately

4. **Track progress**: Compare metrics to previous phases to show improvement trend

5. **Don't blame**: Focus on process improvements, not mistakes. Use "could have" not "should have"

6. **Learn from success too**: Document what went well so it becomes standard practice

## Example Improvements to Propose

**MEMORY.md additions**:
- New pattern discovered (e.g., "check existing test fixtures first")
- Calibration strategy for a specific domain (e.g., physics tests)
- Tool usage pattern (e.g., "use Grep before Read for large files")

**CLAUDE.md additions**:
- Project-specific convention discovered
- Common pitfall to avoid
- Required field for API models

**Skill improvements**:
- Add missing step (e.g., "run mypy in Phase 2")
- Reorder steps for better efficiency
- Add checklist to prevent skipping

**New agents/patterns**:
- If same task is repeated 3+ times, suggest automation
- If a phase is particularly complex, suggest dedicated agent

## Anti-patterns to Avoid

‚ùå **Vague**: "Tests could be better"
‚úÖ **Specific**: "Add parameterization for 5 similar test cases (saves 20 lines, ~2k tokens)"

‚ùå **Unmeasured**: "This took too long"
‚úÖ **Quantified**: "10 minutes spent rewriting async tests to sync (10k tokens). Grep check would catch in 30 seconds."

‚ùå **No action**: "Linting should be earlier"
‚úÖ **Actionable**: "Update implement-feature.md Phase 2: Add 'poetry run mypy src/' after ruff checks"

‚ùå **Blame-focused**: "You should have checked patterns first"
‚úÖ **Process-focused**: "Adding grep pattern check before writing tests would have prevented 10 min rework"
